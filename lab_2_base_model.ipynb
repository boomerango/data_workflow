{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score,roc_auc_score\n",
    "import utils\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./customer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setting grid of selected parameters for iteration\n",
    "# param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "#               'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "#               'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "#               'n_estimators': [50,65,80,100,115,130,150],\n",
    "#               'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "#               'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "# #obtaining default parameters by calling .fit() to XGBoost model instance\n",
    "# xgbc = xgb.XGBClassifier(objective='binary:logistic',\n",
    "#                           booster='gbtree',\n",
    "#                           eval_metric='auc',\n",
    "#                           tree_method='hist',\n",
    "#                           grow_policy='lossguide',\n",
    "#                           use_label_encoder=False)\n",
    "# xgbc.fit(X_train , y_train)\n",
    "\n",
    "# default_params = {}\n",
    "# gparams = xgbc.get_params()\n",
    "\n",
    "# for key in gparams.keys():\n",
    "#     gp = gparams[key]\n",
    "#     default_params[key] = [gp]\n",
    "# #classifier instance of current iteration\n",
    "\n",
    "# clf = GridSearchCV(estimator=xgbc, param_grid=param_grid, scoring='accuracy', return_train_score=True, verbose=1, cv=3)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_from_greedsearch = xgb.XGBClassifier(\n",
    " booster= 'gbtree',\n",
    " enable_categorical=False,\n",
    " eval_metric= 'auc',\n",
    " gamma= 6.4,\n",
    " grow_policy ='lossguide',\n",
    " learning_rate= 0.01,\n",
    " max_depth= 5,\n",
    " n_estimators= 100,\n",
    " objective= 'binary:logistic',\n",
    " tree_method= 'hist',\n",
    " use_label_encoder= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_from_greedsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_from_greedsearch.predict(X_test)\n",
    "\n",
    "test_auc = roc_auc_score(y_test, classifier_from_greedsearch.predict_proba(X_test)[:,1])\n",
    "ttest_accuracy = accuracy_score(y_test, classifier_from_greedsearch.predict(X_test))\n",
    "\n",
    "print(f\"Test AUC/accuracy score: {np.round(test_auc,4)} / {np.round(ttest_accuracy,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"xgb_classifier_from_greedsearch.pkl\"\n",
    "# #saving model\n",
    "pickle.dump(classifier_from_greedsearch, open(file_name, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
